### Kube cluster build for:
# Debian 12
# K8s version 1.30
# docker 5:27.0.3-1
# containerd 1.7.18-1
# Calico (CNI/Networking)

### Server User Account (Non-root)
SVR_USER="dev"

### Kube boostrap ip range
KUBE_CIDR="172.31.0.0/16"

##############################################  the basics  ############################################

# Switch to root
su -

##  Basic stuff  ##
apt update
apt install -y nala && nala upgrade
nala --install-completion bash
nala --show-completion bash
# Only keep the top 5 fastest mirrors
# sudo nala fetch 1,2,3,4,5

# Install Packages
nala install -y gpg curl accountsservice neofetch sudo network-manager curl vim net-tools ca-certificates apt-transport-https

# Aliases
echo "alias ll='ls -la'" >> ~/.bashrc
echo "alias ll='ls -la'" >> /home/$SVR_USER/.bashrc

# Setup non-root user
/sbin/usermod -a -G sudo $SVR_USER
echo "$SVR_USER ALL=(ALL) ALL" >> /etc/sudoers

# Setup Network Manager
echo "managed=true" >> /etc/NetworkManager/NetworkManager.conf
systemctl restart NetworkManager

# Kill the swap space
swapoff -a
sed -i 's_/swap.img_#/swap.img_g' /etc/fstab
(crontab -l 2>/dev/null; echo "@reboot /sbin/swapoff -a") | crontab - || true

####################################  Containerd install  ########################################
## REF: https://docs.docker.com/engine/install/debian/

# Add Docker's official GPG key:
install -m 0755 -d /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/debian/gpg -o /etc/apt/keyrings/docker.asc
chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/debian \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Update and install
nala upgrade -y
nala install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

# Add non-root user to the docker group
usermod $SVR_USER -aG docker

# Apt hold required packages:
apt-mark hold docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin

################################### Kube install ################################
# REF: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

# Add Kube repo keys:
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

# Add kube repo
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

nala upgrade -y
nala install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl

systemctl enable --now kubelet

# Blow away containerd configs:
# rm -f /etc/containerd/configs.toml

# Update kernel for CRI/CNI
cat <<EOF | tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

modprobe overlay
modprobe br_netfilter

touch /etc/sysctl.d/k8s.conf
chmod 744 /etc/sysctl.d/k8s.conf

cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sysctl -p /etc/sysctl.d/k8s.conf

## COMMENT OUT DISABLED PLUGINS
#disabled_plugins = ["cri"]
sed -i 's_/disabled_plugins_#/disabled_plugins_g' /etc/containerd/config.toml

# Update containerd config.toml
cat <<EOF | tee /etc/containerd/config.toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
          runtime_type = "io.containerd.runc.v2"
          runtime_engine = ""
          runtime_root = ""
          privileged_without_host_devices = false
          base_runtime_spec = ""

[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
          SystemdCgroup = true
EOF

# restart containerd after new config.toml
systemctl restart containerd.service

############################## Kube Bootstrap ####################################
# REF: https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/

kubeadm init --pod-network-cidr=$KUBE_CIDR | tee /tmp/bootstrap_log.txt
grep -a1 "kubeadm join" /tmp/bootstrap_log.txt

############################## Install Kube CNI (Calico) #########################
### REF: https://docs.tigera.io/calico/latest/getting-started/kubernetes/quickstart

mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

# Install Calico operator
### REF: https://docs.tigera.io/calico/latest/reference/installation/api
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/tigera-operator.yaml

# Install Calico CRDs
kubectl create -f https://raw.githubusercontent.com/projectcalico/calico/v3.28.0/manifests/custom-resources.yaml

##### STUCK 22 JUL, kubelet shitting bed





















#########################################  SSH Setup  #####################################################

# ssh-keygen

# echo "192.168.1.111 svr1" >> /etc/hosts
# echo "192.168.1.112 svr2" >> /etc/hosts
# echo "192.168.1.113 svr3" >> /etc/hosts

# ssh-copy-id svr1
# ssh-copy-id svr2
# ssh-copy-id svr3





## LETS MAKE A BABY
## Thats what Jeff said, but I'm gonna say "little hand says its time to rock and roll"

# systemctl restart crio

# W // We need a command here to do the kubeinit, cut the join code, and paste it into the kube_join.txt command

# Run as sudo $SVR_USER
mkdir -p $HOME/.kube
cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
chown $(id -u):$(id -g) $HOME/.kube/config

# W // opscheck with the command 
kubectl get nodes

cp $HOME/.kube/config /etc/dev_range/workdir/.
chmod 777 /etc/dev_range/workdir/config
cp /etc/kubernetes/admin.conf /etc/dev_range/workdir/.
chmod 777 /etc/dev_range/workdir/admin.conf

# Deploy Flannel overlay router
hostname | grep elastic1 > /dev/null && kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# Deploy Metrics server - insecure-tls mode
hostname | grep elastic1 > /dev/null && kubectl apply -f https://raw.githubusercontent.com/techiescamp/kubeadm-scripts/main/manifests/metrics-server.yaml

grep -qxF 'export KUBECONFIG=/etc/kubernetes/admin.conf' ~/.bashrc || echo 'export KUBECONFIG=/etc/kubernetes/admin.conf' >> ~/.bashrc

## // ELASTIC 2 and 3 NOTES // ##
# W // For obvious reasons the tokens will not be the same

kubeadm join 10.112.100.201:6443 --token 9xc85z.nvbxpov8bdm1b9ha \
        --discovery-token-ca-cert-hash sha256:e86dbb8638438771b7ef66b3a59ecb5c34d26bd89bab3b936010de6c46131823

mkdir -p $HOME/.kube
scp groot@10.112.100.201:/etc/dev_range/workdir/config $HOME/.kube/.
scp groot@10.112.100.201:/etc/dev_range/workdir/admin.conf /etc/kubernetes/.

grep -qxF 'export KUBECONFIG=/etc/kubernetes/admin.conf' ~/.bashrc || echo 'export KUBECONFIG=/etc/kubernetes/admin.conf' >> ~/.bashrc


##  Cleanup Commands ##
apt remove -y cri-o cri-o-runc cri-tools kubeadm kubelet kubectl
rm -rf /etc/cni/net.d
iptables -F
rm -rf ~/.kube/*
rm -rf /etc/kubernetes/
rm -rf /etc/containerd
rm -rf /etc/modules-load.d/k8s.conf
rm -rf /etc/sysctl.d/k8s.conf


# ALL NODES --- Restart CRI-O in case you have a networking issue
# systemctl restart crio

## Common issues here:
# - Found multiple CRI endpoints on the host. >> You need to check for docker, crio, and containerd services. Only one can be running at kubeadm "init" or "join"
# - Something about "invalid arguments from /proc* >> you need to make sure your config file has the right settings, you've done sysctl --system, and compelted a reboot.
#   - For more on this issue, check line 
# cat /etc/kubernetes/admin.conf
# kubeadm reset if you fuck up the master, do cleanup actions up top
# also run: rm -rf /etc/cni/net.d/
# flannel requires the "--pod-network-cidr=10.244.0.0/16"
# if you are too slow with the "join.sh" script, the token will expire. make a new one with:
# kubeadm token create --print-join-command

## Remove all Taints // if you want to schedule apps on the master node by default
# kubectl taint nodes elastic1 key-

## Create a default storage class

# mkdir /etc/dev_range/workdir/kube_configs

# cat <<EOF | tee /etc/dev_range/workdir/kube_configs/default-storage-class.yaml
# apiVersion: storage.k8s.io/v1
# kind: StorageClass
# metadata:
#   name: local-storage
# provisioner: kubernetes.io/no-provisioner
# parameters:
#   type: gp2
# reclaimPolicy: Retain
# allowVolumeExpansion: true
# mountOptions:
#   - debug
# volumeBindingMode: WaitForFirstConsumer
# EOF

# kubectl apply -f /etc/dev_range/workdir/kube_configs/default-storage-class.yaml
# kubectl patch storageclass local-storage -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'


# kubeadm join 10.112.100.201:6443 --token 9xc85z.nvbxpov8bdm1b9ha \
#         --discovery-token-ca-cert-hash sha256:e86dbb8638438771b7ef66b3a59ecb5c34d26bd89bab3b936010de6c46131823
